# 5. Concurrency mathematics
## 5.1. Little's Law Applied Per Layer

$$L = \lambda \times W$$

| Layer | λ (TPS) | W (avg) | L (steady-state) | Configured Limit | Utilization |
|---|---|---|---|---|---|
| gRPC submit ingress | 1,000 | 25ms (P99) | **25** | 32 | 78% |
| Master DB connections | 1,000 | 30ms (P99 burst) | **30** | 128 | 23.4% |
| Accounting gRPC channel | 1,000 | 10ms | **10** | 500 (5×100 streams) | 2% |
| Bank transaction | 20* | 200ms | **4** | 10 (OkHttp pool) | 40% |


### 5.2 Amdahl  — Parallelism Ceiling

Make sure you don't misunderstanding: Payment Engine system not parallelizing within a transaction, but by running many transaction at the same time in parallel. Why ?

```
Because in a financial system, steps within one transaction depend on each other (you must deduct before you add — otherwise you give money away for free). Forcing them to be sequential is not a limitation — it's a correctness requirement. The system is designed to scale by adding more transactions in parallel, not by making one transaction faster.

```

The Saga Engine is a sequential state machine per transaction. Each transaction's saga steps are **serialized** (step N+1 cannot start until step N completes). If a transaction has 3 saga steps (DEDUCT → ADD → REVERT):

$$S(N) = \frac{1}{(1-p) + \frac{p}{N}}$$

Plugging into the formula: $$S(N) = \frac{1}{1 + 0} = 1$$

Speedup = 1 — meaning no matter how many threads you throw at a single transaction, it won't go faster.

**Each transaction is 100% sequential**. The system achieves throughput via **transaction-level parallelism** (different transactions run concurrently), not intra-transaction parallelism.


### 4.3 Universal Scalability Law (USL) — Queueing + Coherence

At high thread counts, the `ArrayBlockingQueue` in `DirectPool` introduces **queueing delay**:

$$C(N) = \frac{N}{1 + \alpha(N-1) + \beta N(N-1)}$$

Where:
- $\alpha$ = contention coefficient (from lock in `RateLimiter`)
- $\beta$ = coherence coefficient (from `ArrayBlockingQueue` internal locks)

let's take queueSize=512:
- When poolSize threads are all busy and the queue is filling: producers spin on queue.put() (blocking)
- At`poolSize = P and queue depth = Q, max in-flight = P + Q = poolSize + 512
- Throughput peaks at `poolSize` threads and **degrades** as queue backs up due to increased per-task latency (tasks wait in queue before executing)
